# 🧠 Blend Property Prediction using Machine Learning
## Shell.ai-Hackathon-2025

This project aims to predict the **blend properties** of materials using machine learning models like **Random Forest** and **XGBoost**.  
The dataset includes information about multiple components and their physical or chemical properties, and the goal is to accurately estimate the resulting blend properties.

---

## 📂 Project Structure
- train.csv # Training dataset with input features and target values
- test.csv # Test dataset for generating predictions
- submission.csv # Final output predictions from the best model
- Shell.ai_Hackathon_2025.ipynb # Jupyter Notebook containing code
- README.md # Project documentation



---

## 🚀 Key Features
- End-to-end **machine learning pipeline** (data loading → model training → prediction).
- Handles **multiple component features** and their **property relationships**.
- Compares **Random Forest** and **XGBoost** models for performance.
- Evaluates models using **Root Mean Squared Error (RMSE)**.
- Automatically exports predictions to a `submission.csv` file.

---

## 🧾 Dataset Overview
- Each record represents a blend consisting of **5 components**.
- For each component:
  - `ComponentN_fraction`: Fraction or proportion of the component.
  - `ComponentN_PropertyX`: Numerical features (e.g., physical/chemical attributes).
- Target columns:  
  - `BlendProperty1` to `BlendProperty10`

---

## ⚙️ Steps Performed

1. **Load the datasets** (`train.csv` and `test.csv`).
2. **Check for missing values** and clean data.
3. **Split features and target variables**.
4. **Train and evaluate**:
   - ✅ **Random Forest Regressor**
   - ⚡ **XGBoost Regressor**
5. **Evaluate using RMSE**.
6. **Select best-performing model** (XGBoost in this case).
7. **Generate and save predictions** in `submission.csv`.

---

## 📊 Results
| Model               | RMSE   |
|----------------------|--------|
| Random Forest        | 0.5303 |
| **XGBoost (Best)**   | **0.2504** |

✅ XGBoost achieved the lowest error and was used for the final submission.

---

## 💡 Technologies Used
- Python 🐍  
- Pandas  
- NumPy  
- Scikit-learn  
- XGBoost  
- Matplotlib / Seaborn (for analysis & visualization)

---

## 📁 Output
The file `submission.csv` contains the final predictions generated by the trained **XGBoost** model.

Example:
```csv
ID,BlendProperty1,BlendProperty2,...,BlendProperty10
1,0.452,0.327,...,0.718
2,0.563,0.291,...,0.802
```
--- 

## 🧑‍💻 Author
- Maryam Naseem
- 🎓 BSIT Student | 🌱 Aspiring Data Scientist
- 📧 www.linkedin.com/in/maryam--naseem

---

## ⭐ Acknowledgment
This project was completed as part of the BUILDABLES Fellowship Program (Data Science Track).
It provided valuable hands-on experience in regression modeling and feature handling for structured datasets.

